{
  "name": "jupyter",
  "description": "Jupyter notebook management for AI development and content analysis",
  "version": "1.0.0",
  "phase": 2,
  "priority": "high",
  "dependencies": {
    "runtime": "python",
    "packages": [
      "jupyter-mcp-server",
      "jupyter",
      "ipykernel",
      "pandas",
      "numpy",
      "scikit-learn",
      "openai",
      "anthropic",
      "transformers",
      "torch",
      "matplotlib",
      "seaborn"
    ],
    "system": ["python3", "pip3"]
  },
  "configuration": {
    "command": "python",
    "args": ["-m", "jupyter_mcp_server"],
    "environment": {
      "JUPYTER_CONFIG_DIR": "./jupyter-config",
      "JUPYTER_DATA_DIR": "./jupyter-data",
      "JUPYTER_RUNTIME_DIR": "./jupyter-runtime",
      "JUPYTER_MAX_MEMORY": "4GB",
      "JUPYTER_TIMEOUT": "300",
      "JUPYTER_KERNEL_TIMEOUT": "60"
    },
    "security": {
      "allowed_kernels": ["python3", "python3-ai"],
      "restricted_imports": ["os.system", "subprocess", "eval", "exec"],
      "max_execution_time": 300,
      "max_memory_usage": "4GB",
      "network_access": "restricted",
      "file_access": "sandboxed"
    }
  },
  "use_cases": {
    "ai_content_analysis": {
      "description": "AI-powered content analysis for quiz generation (Phase 2.2)",
      "operations": ["createNotebook", "executeCell", "getResults"],
      "examples": {
        "analyze_pdf_content": {
          "notebook": "content-analysis",
          "cells": [
            {
              "type": "code",
              "content": "import PyPDF2\nimport openai\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Load and analyze PDF content\nwith open('./uploads/materials/lesson1.pdf', 'rb') as file:\n    reader = PyPDF2.PdfReader(file)\n    text = ''.join([page.extract_text() for page in reader.pages])\n\nprint(f'Extracted {len(text)} characters from PDF')"
            },
            {
              "type": "code",
              "content": "# Generate quiz questions using AI\nresponse = openai.ChatCompletion.create(\n    model='gpt-4',\n    messages=[{\n        'role': 'user',\n        'content': f'Generate 10 multiple choice questions from this content: {text[:2000]}'\n    }]\n)\n\nquestions = response.choices[0].message.content\nprint(f'Generated questions: {questions}')"
            }
          ]
        }
      }
    },
    "adaptive_learning_analysis": {
      "description": "Analyze student performance for adaptive learning (Phase 2.3)",
      "operations": ["executeCell", "visualizeData", "exportResults"],
      "examples": {
        "student_performance_analysis": {
          "notebook": "adaptive-learning",
          "cells": [
            {
              "type": "code",
              "content": "import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Load student performance data\ndf = pd.read_csv('./data/student-performance.csv')\nprint(f'Loaded {len(df)} student records')"
            },
            {
              "type": "code",
              "content": "# Analyze learning patterns\nfeatures = ['quiz_score', 'time_spent', 'attempts', 'help_requests']\nX = df[features].fillna(0)\n\n# Cluster students by learning patterns\nkmeans = KMeans(n_clusters=3, random_state=42)\ndf['learning_cluster'] = kmeans.fit_predict(X)\n\n# Visualize clusters\nplt.figure(figsize=(10, 6))\nfor cluster in range(3):\n    cluster_data = df[df['learning_cluster'] == cluster]\n    plt.scatter(cluster_data['quiz_score'], cluster_data['time_spent'], \n               label=f'Cluster {cluster}', alpha=0.7)\nplt.xlabel('Quiz Score')\nplt.ylabel('Time Spent (minutes)')\nplt.title('Student Learning Patterns')\nplt.legend()\nplt.savefig('./outputs/learning-clusters.png')\nplt.show()"
            }
          ]
        }
      }
    },
    "ai_feedback_generation": {
      "description": "Generate personalized AI feedback (Phase 2.3)",
      "operations": ["executeCell", "processResults"],
      "examples": {
        "personalized_feedback": {
          "notebook": "ai-feedback",
          "cells": [
            {
              "type": "code",
              "content": "def generate_personalized_feedback(student_id, quiz_results, learning_style):\n    # Analyze student's performance\n    score = quiz_results['score']\n    weak_areas = quiz_results['weak_topics']\n    strong_areas = quiz_results['strong_topics']\n    \n    # Generate AI feedback\n    prompt = f\"\"\"\n    Student scored {score}% on the quiz.\n    Weak areas: {', '.join(weak_areas)}\n    Strong areas: {', '.join(strong_areas)}\n    Learning style: {learning_style}\n    \n    Generate encouraging, specific feedback with study recommendations.\n    \"\"\"\n    \n    response = openai.ChatCompletion.create(\n        model='gpt-4',\n        messages=[{'role': 'user', 'content': prompt}]\n    )\n    \n    return response.choices[0].message.content"
            }
          ]
        }
      }
    },
    "data_preprocessing": {
      "description": "Data preprocessing for AI models",
      "operations": ["loadData", "cleanData", "featureEngineering"],
      "examples": {
        "course_content_preprocessing": {
          "notebook": "data-preprocessing",
          "cells": [
            {
              "type": "code",
              "content": "import pandas as pd\nimport re\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Load course content\ncourses_df = pd.read_csv('./data/courses.csv')\nlessons_df = pd.read_csv('./data/lessons.csv')\n\nprint(f'Loaded {len(courses_df)} courses and {len(lessons_df)} lessons')"
            },
            {
              "type": "code",
              "content": "# Clean and preprocess text content\ndef clean_text(text):\n    if pd.isna(text):\n        return ''\n    # Remove HTML tags\n    text = re.sub(r'<[^>]+>', '', text)\n    # Remove special characters\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n    # Convert to lowercase\n    text = text.lower().strip()\n    return text\n\nlessons_df['clean_content'] = lessons_df['content'].apply(clean_text)\nlessons_df['content_length'] = lessons_df['clean_content'].str.len()\n\nprint('Text preprocessing completed')"
            }
          ]
        }
      }
    }
  },
  "notebooks": {
    "templates": {
      "content-analysis": {
        "description": "Template for analyzing course content",
        "cells": [
          "# Content Analysis Notebook\n\nThis notebook analyzes course content for AI-powered features.",
          "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport openai\n\n# Set up plotting\nplt.style.use('seaborn-v0_8')\nsns.set_palette('husl')",
          "# Load course content\n# TODO: Replace with actual data loading",
          "# Analyze content structure\n# TODO: Add content analysis code",
          "# Generate insights\n# TODO: Add AI-powered insights"
        ]
      },
      "adaptive-learning": {
        "description": "Template for adaptive learning analysis",
        "cells": [
          "# Adaptive Learning Analysis\n\nThis notebook analyzes student performance for adaptive learning.",
          "import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt",
          "# Load student data\n# TODO: Replace with actual data loading",
          "# Analyze learning patterns\n# TODO: Add clustering and pattern analysis",
          "# Generate recommendations\n# TODO: Add personalized recommendations"
        ]
      },
      "ai-feedback": {
        "description": "Template for AI feedback generation",
        "cells": [
          "# AI Feedback Generation\n\nThis notebook generates personalized feedback using AI.",
          "import openai\nimport pandas as pd\nfrom typing import Dict, List",
          "# Define feedback generation functions\n# TODO: Add feedback generation logic",
          "# Test feedback generation\n# TODO: Add testing code"
        ]
      }
    }
  },
  "monitoring": {
    "health_check": {
      "command": "jupyter --version",
      "interval": 60,
      "timeout": 10
    },
    "metrics": {
      "notebook_executions_total": "Counter of notebook executions",
      "cell_execution_duration": "Histogram of cell execution times",
      "active_kernels": "Gauge of active Jupyter kernels",
      "memory_usage_bytes": "Gauge of memory usage",
      "ai_api_calls_total": "Counter of AI API calls",
      "ai_api_cost_total": "Counter of AI API costs"
    },
    "alerts": {
      "high_memory_usage": {
        "condition": "memory_usage_bytes > 3GB",
        "duration": "5m",
        "severity": "warning"
      },
      "kernel_timeout": {
        "condition": "cell_execution_duration > 300s",
        "duration": "1m",
        "severity": "warning"
      },
      "high_ai_costs": {
        "condition": "ai_api_cost_total > 100",
        "duration": "1h",
        "severity": "critical"
      }
    }
  },
  "integration": {
    "ai_services": {
      "openai": {
        "models": ["gpt-4", "gpt-3.5-turbo", "text-embedding-ada-002"],
        "use_cases": ["content_analysis", "quiz_generation", "feedback"]
      },
      "anthropic": {
        "models": ["claude-3-sonnet", "claude-3-haiku"],
        "use_cases": ["content_analysis", "educational_content"]
      }
    },
    "data_sources": {
      "filesystem": {
        "use_case": "Load course materials and student data",
        "operations": ["readFile", "listFiles"]
      },
      "database": {
        "use_case": "Query student performance and course data",
        "operations": ["query", "insert", "update"]
      }
    }
  },
  "testing": {
    "unit_tests": [
      {
        "name": "test_notebook_creation",
        "description": "Test notebook creation and basic operations",
        "steps": [
          "Create new notebook",
          "Add code cell",
          "Execute cell",
          "Verify output",
          "Clean up notebook"
        ]
      },
      {
        "name": "test_ai_integration",
        "description": "Test AI service integration",
        "steps": [
          "Set up AI client",
          "Make test API call",
          "Verify response format",
          "Check cost tracking"
        ]
      }
    ],
    "integration_tests": [
      {
        "name": "test_content_analysis_workflow",
        "description": "Test complete content analysis workflow",
        "steps": [
          "Load test PDF via filesystem server",
          "Create analysis notebook",
          "Execute content extraction",
          "Generate quiz questions",
          "Verify output quality"
        ]
      }
    ]
  },
  "best_practices": {
    "security": [
      "Sandbox all notebook executions",
      "Restrict network access for untrusted code",
      "Monitor and limit resource usage",
      "Validate all inputs before execution",
      "Never expose API keys in notebook outputs"
    ],
    "performance": [
      "Set execution timeouts for all cells",
      "Monitor memory usage and clean up",
      "Cache expensive computations",
      "Use vectorized operations when possible",
      "Limit concurrent notebook executions"
    ],
    "ai_integration": [
      "Monitor AI API costs and usage",
      "Implement fallback strategies for AI failures",
      "Cache AI responses when appropriate",
      "Validate AI outputs before using",
      "Implement human review for critical AI decisions"
    ]
  }
}